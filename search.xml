<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HDFS特点]]></title>
    <url>%2F2018%2F01%2F18%2FHDFS%E8%AF%A6%E8%A7%A3%20%2F</url>
    <content type="text"><![CDATA[HDFS 特点 123456高容错性高吞吐量故障的检测和自动快速恢复流式的数据访问大数据集一次写入,多次读写 不适用的场景 123不支持大量小文件的存储不适合随机读写不适合随意修改 组成 123hdfs是一个主从结构的体系,一个HDFS的集群由以下部分组成：NameNode(名字节点):一个用来管理文件的名字空间和调节客户端访问文件的主服务器DataNode(数据节点):一个或多个,用来管理存储 NameNode1234NameNode是管理者,一个Hadoop集群有一个NameNode节点,是一个通常在HDFS实例中的单独机器上运行的软件.它负责管理文件系统名字空间和控制外部客户机的访问NameNode决定是否将文件映射到DataNode的复制块上.实际的I/O事务并没有经过NameNode,只有表示DataNode和块的文件映射的元数据经过NameNode。当外部客户机发送请求要求创建文件时,NameNode会以块标识和该块的第一个副本的DataNode IP地址作为响应.这个NameNode还会通知其他将要接收该块的副本的DataNode 主要功能： 1231.NameNode提供名称查询服务,它是一个Jetty服务器2.NameNode保存metadata信息.具体包括:文件owership和permissons;文件包含哪些块,Block保存在哪个DataNode(由DataNode启动时上报)3.NameNode的metadata信息在启动后会加载在内存 DataNode123Hadoop集群中包含一个NameNode和大量的DataNode,DataNode通常以机架的形式组织,机架通过一个交换机将所有系统连接起来DataNode响应来自HDFS客户机的读写请求,它们还响应来自NameNode的创建、删除和复制块的命令 DataNode的功能： 1231：保存Block，每一个块对应一个元数据信息文件。这个文件主要描述这个块属于哪个文件,第几个块等信息2：启动DataNode线程的时候会向NameNode汇报Block信息3：通过向NameNode发送心跳保持其联系(3秒一次),如果NameNode10分钟没有收到DataNode的心跳,则认为其已经lost，并将其上的Block复制到其他DataNode]]></content>
      <categories>
        <category>HDFS</category>
      </categories>
      <tags>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop集群双NameNode]]></title>
    <url>%2F2018%2F01%2F18%2FHadoop%E9%9B%86%E7%BE%A4%E5%8F%8CNameNode%2F</url>
    <content type="text"><![CDATA[环境 123456789hdp21 192.168.95.21hdp22 192.168.95.22hdp23 192.168.95.23hdp24 192.168.95.24hdp25 192.168.95.25时间网络同步、关闭selinux创建用户hadoop，密码fujghadoop 用户免密登录我准备把所有的文件都放在home目录下 Hadoop2.7.3 12345192.168.95.21 hdp21 主NameNode192.168.95.22 hdp22 备用NameNode192.168.95.23 hdp23 DataNode192.168.95.24 hdp24 DataNode192.168.95.25 hdp25 DataNode 1.准备1234567891，解压安装包到home目录tar –zxvf hadoop-2.7.3.tar.gz –C /home/2，修改home的权限chmod 777 /home3，创建目录mkdir -pv /home/dfs/&#123;data,name&#125;mkdir /home/tmpmkdir -pv /home/hadoop-2.7.3/&#123;journal,mapred_local,mapred_system,mr-history&#125;mkdir -pv /home/hadoop-2.7.3/mr-history/&#123;done,tmp&#125; 2. 编辑配置文件2.1 core-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;configuration&gt; &lt;property&gt; &lt;!-- hdfs访问端口，这里看hdfs-site.xml中配置的端口，双机 --&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 临时文件目录 --&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 缓存的大小，单位为byte，默认4k，线上设置为40k，这里设置4k --&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hdp21:2181,hdp22:2181,hdp23:2181,hdp24:2181,hdp25:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 用户代理机制 属组 --&gt; &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt; &lt;value&gt;hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 用户代理机制 hosts --&gt; &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt; &lt;value&gt;192.168.95.21&lt;/value&gt; &lt;/property&gt; &lt;!-- snappy 文件压缩 --&gt; &lt;!--&lt;property&gt; &lt;name&gt;io.compression.codecs&lt;/name&gt; &lt;value&gt; org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.BZip2Codec, org.apache.hadoop.io.compress.SnappyCodec &lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 2.2 hdfs-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定hdfs的nameservice为ns，要与core-site.xml中的名字一致 --&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- ns下面配置两个nameNode，nn1、nn2 --&gt; &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt; &lt;value&gt;hdp21:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- nn1的HTTP通信地址 --&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt; &lt;value&gt;hdp21:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt; &lt;value&gt;hdp22:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- nn2的HTTP通信地址 --&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt; &lt;value&gt;hdp22:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定NameNode的元数据 在JournalNode上的存放位置，使用以下3个节点存储 --&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://hdp23:8485;hdp24:8485;hdp25:8485/ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/journal&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 开启NameNode故障时自动切换 --&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 失败自动切换实现方式 --&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 配置隔离机制，如果ssh是默认22端口，value直接写sshfence即可 --&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 使用隔离机制时，需要ssh免密登录 --&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 元数据文件目录，默认为//$&#123;hadoop.tmp.dir&#125;/dfs/name，这里的hadoop.tmp.dir是core-site.xml中配置的临时文件目录 --&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 数据目录 --&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 副本的冗余数量，正常应该是三个 --&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 在nn和dn上开启webHDFS (REST API) 功能，不是必须 --&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 数据节点 追加 start --&gt; &lt;property&gt; &lt;!-- 是否开启数据节点追加，默认为true，当节点很少(即，节点宕掉了没有新的节点可提供)时，应该关闭 --&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 数据节点追加，当上一个设置为true时起作用 --&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;/name&gt; &lt;value&gt;NEVER&lt;/value&gt; &lt;/property&gt; &lt;!-- 数据节点 追加 end --&gt; &lt;property&gt; &lt;!-- 权限检查开关，只有在有权限的环境中有用 --&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- webserver使用的用户名，','分隔添加用户组 --&gt; &lt;name&gt;dfs.web.ugi&lt;/name&gt; &lt;value&gt;hadoop,hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 超时时间，单位 毫秒 --&gt; &lt;name&gt;dfs.socket.timeout&lt;/name&gt; &lt;value&gt;240000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定用于在DataNode间传输block数据的最大线程数，默认4096 线上配置为40960 --&gt; &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 打开文件数量上限，不能超过系统打开文件数设置 线上配置40960 --&gt; &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- datanode同时处理客户端请求线程数，默认为10 线上配置500 --&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- namenode线程数，越大消耗内存越大 线上配置500 --&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt; &lt;!-- 动态增删节点，下面两项配置，运行hadoop dfsadmin -refreshNodes 即可使其生效 --&gt; &lt;property&gt; &lt;!-- 节点写在文件中 --&gt; &lt;name&gt;dfs.hosts&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/etc/hadoop/slaves&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 要删除的节点写在文件中 --&gt; &lt;name&gt;dfs.hosts.exclude&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/etc/hadoop/exclude-slaves&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 2.3 mapred-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定map reduce运行在YARN上 --&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- mapreduce共享目录，MapReduce的控制文件 --&gt; &lt;name&gt;mapred.system.dir&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/mapred_system&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- MapReduce产生的中间数据存放目录,以,号隔开,hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉 --&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/mapred_local&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- mapreduce历史作业服务:端口 --&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hdp21:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- mapreduce历史作业 web ui 服务:端口 --&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hdp21:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- mapreduce正在运行作业信息目录 --&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/mr-history/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- mapreduce已完成作业信息目录 --&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;/home/hadoop-2.7.3/mr-history/done&lt;/value&gt; &lt;/property&gt; &lt;!-- JVM参数 --&gt; &lt;property&gt; &lt;!-- 每个map或reduce使用的内存数量，线上512m --&gt; &lt;name&gt;mapred.child.java.opts&lt;/name&gt; &lt;value&gt;-Xmx200M&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- reduce使用的内存数量，线上512m --&gt; &lt;name&gt;mapred.reduce.child.java.opts&lt;/name&gt; &lt;value&gt;-Xmx200M&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- map使用的内存数量，线上512m --&gt; &lt;name&gt;mapred.map.child.java.opts&lt;/name&gt; &lt;value&gt;-Xmx200M&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 2.4 yarn-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;!-- 辅助服务，扩展自己的功能 --&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 开启RM高可用，ha高可用集群，这里是双机 --&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 自动故障切换 --&gt; &lt;name&gt;yarn.resourcemanager.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- --&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;hdp23:2181,hdp24:2181,hdp25:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定rm1的地址 --&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;hdp21&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定rm2的地址 --&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;hdp22&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定RM的cluster集群 id --&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 该节点上YARN可使用的物理内存总量，默认是8192（MB），YARN不会智能的探测节点的物理内存总量，线上是16372 --&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 2.5 slaves123hdp23hdp24hdp25 2.6 修改hadoop-env.sh1234vim /home/hadoop-2.7.3/etc/hadoop/hadoop-env.sh把原来的export JAVA_HOME=$&#123;JAVA_HOME&#125;修改为export JAVA_HOME= /usr/local/jdk1.7.0_71即真实的jdk安装路径 2.7 复制配置到其他节点12345cd /home/scp -r hadoop-2.7.3/ hdp22:/home/scp -r hadoop-2.7.3/ hdp23:/home/scp -r hadoop-2.7.3/ hdp24:/home/scp -r hadoop-2.7.3/ hdp25:/home/ 3 环境变量123456su rootvim /etc/profile.d/hadoop.shexport HADOOP_HOME=/home/hadoop-2.7.3export PATH=$PATH:$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin复制到其他节点：scp /etc/profile.d/hadoop.sh hdp22: /etc/profile.d/执行使配置立即生效 . /etc/profile.d/hadoop.sh 4 为启动准备4.1 zookeeper12启动zookeeper，zk-bat.sh startZookeeper已经安装完成 zk-bat.sh是我写的启动脚本 4.2 创建zk命名空间12在主NameNode节点上执行（创建命名空间）：hdfs zkfc -formatZK 4.3 JournalNode123在各个DataNode节点上执行（启动journalnode）：hadoop-daemon.sh start journalnode使用jps查看服务是否启动 4.4 格式化hdfs12格式化namenode和journalnode目录hdfs namenode -format ns 4.5 启动namenode123456781，在主namenode节点启动namenode进程（hdp21，只在一个NameNode上执行即可）hadoop-daemon.sh start namenode2，复制主NameNode（在hdp22上，把备namenode节点的目录格式化并把元数据从主namenode节点copy过来，并且这个命令不会把journalnode目录再格式化了）：hdfs namenode –bootstrapStandby3，启动备namenode进程（在hdp22上执行）hadoop-daemon.sh start namenode4，在两个NameNode上都执行：hadoop-daemon.sh start zkfc 4.6 启动DataNode12在所有的DataNode上执行（启动datanode）：hadoop-daemon.sh start datanode 5 启停1234启动start-dfs.sh停止stop-dfs.sh 6 监控等 hdp21主NameNode 12Hdfs浏览器访问地址：http://hdp21:50070 hdp22备NameNode 12Hdfs浏览器访问地址：http://hdp22:50070 测试NameNode双机杀掉主NameNode，即hdp21上的NameNode进程，浏览器查看hdp22的状态 1.在hdp21上jps，找到NameNode进程id并杀掉 2.浏览器查看备NameNode状态 备用NameNode已经启动了！！！]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装hadoop2.7.5（单节点）]]></title>
    <url>%2F2018%2F01%2F11%2FCentos7%E5%AE%89%E8%A3%85hadoop2.7.5%EF%BC%88%E5%8D%95%E8%8A%82%E7%82%B9%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.安装Java JDK12345678910111213#编辑配置文件vim /etc/profile #添加以下内容export JAVA_HOME=/usr/local/java/jdk1.7.0_79export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar#使环境变量生效source /etc/profile#查看环境变量配置是否成功java -version 2.创建一个新用户12345#新建用户useradd hadoop#设置密码passwd hadoop 3.下载Hadoophadoop-2.7.5.tar.gz 123456789#解压tar包tar xfz hadoop-2.7.5.tar.gz#移动到/opt目录mkdir /opt/hadoopmv hadoop-2.7.5/* /opt/hadoop#更改目录所有者为hadoopchown -R hadoop:hadoop /opt/hadoop/ 4.配置ssh免密登录123456789101112131415*#登录hadoop用户su - hadoop#首先，生成SSH秘钥，生成的私钥文件默认位置是~/.ssh/id_rsa.pubssh-keygen -t rsa #将私钥写入~/.ssh/authorized_keyscat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys#尝试使用ssh登陆localhost，应该不再需要输入密码ssh localhost#非root用户设置本地ssh免密登录失败，需要给authorized_keys文件授权chmod 710 ~/.ssh/authorized_keysssh localhost 5.配置hadoop 添加环境变量，编辑/etc/profile文件 1vim /etc/profile 配置hadoop环境变量 12345678export HADOOP_HOME=/opt/hadoopexport HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin 使环境变量生效 1source /etc/profile 编辑hadoop-env.sh文件 12cd $HADOOP_HOME/etc/hadoopvim hadoop-env.sh 将export JAVA_HOME=${JAVA_HOME}改为如下 1export JAVA_HOME=/usr/local/java/jdk1.7.0_79 编辑core-site.xml文件，configuration中的内容 123456&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 编辑hdfs-site.xml文件，configuration中的内容 12345678910111213141516&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/hadoopdata/namenode&lt;/value&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/hadoopdata/datanode&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 创建目录 123mkdir /opt/hadoop/hadoopdatamkdir /opt/hadoop/hadoopdata/namenodemkdir /opt/hadoop/hadoopdata/datanode 创建mapred-site.xml文件 1cp mapred-site.xml.template mapred-site.xml 编辑mapred-site.xml文件，configuration中的内容 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 编辑yarn-site.xml文件，configuration中的内容 1234567&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt; &lt;/configuration&gt; 初始化HDFS文件系统 1hdfs namenode -format 6.启动服务1234567891011#进入sbin文件夹cd /opt/hadoop/sbin#启动Hadoop服务start-dfs.sh#启动yarnstart-yarn.sh#查看服务运行状态jps 7.测试访问主机端口50070或8088查看]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jquery+css代替iframe]]></title>
    <url>%2F2018%2F01%2F05%2Fjquery%2Bcss%E4%BB%A3%E6%9B%BFiframe%2F</url>
    <content type="text"><![CDATA[jquery+css代替iframe 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;script src="http://cdn.static.runoob.com/libs/jquery/1.10.2/jquery.min.js"&gt;&lt;/script&gt;&lt;style type="text/css"&gt; * &#123; margin: 0; padding: 0; &#125; div &#123; text-align: center; font-size: 30px; &#125; .header, .footer &#123; width: 100%; height: 100px; line-height: 100px; background-color: red; &#125; .leftcontent &#123; width: 20%; position: absolute; top: 100px; bottom: 0px; background-color: yellow; &#125; .rightcontent&#123; width: 80%; position: absolute; top: 100px; left: 20%; bottom: 0px; background-color: grey; &#125;&lt;/style&gt;&lt;body&gt;&lt;div class="header"&gt;头部&lt;/div&gt;&lt;div class="leftcontent"&gt; &lt;ul class="nav navbar-nav" id="indexMenu"&gt; &lt;li&gt;&lt;a target="right/1.html"&gt;首页&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="right/2.html"&gt;新闻&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="right/3.html"&gt;留言&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div id="iframeContent" class="rightcontent"&gt;&lt;/div&gt;&lt;/body&gt;&lt;script&gt; $(function()&#123; $.get("right/1.html",function(data)&#123; $("#iframeContent").html(data);//初始化加载界面 &#125;); $('#indexMenu li').click(function()&#123;//点击li加载界面 var current = $(this), target = current.find('a').attr('target'); // 找到链接a中的targer的值 $.get(target,function(data)&#123; $("#iframeContent").html(data); &#125;); &#125;); &#125;);&lt;/script&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>代替iframe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 常用命令]]></title>
    <url>%2F2017%2F10%2F19%2Fdocker%2F</url>
    <content type="text"><![CDATA[摘要 Docker 常用命令简单记录。 Docker容器命令12345678910111213docker images 查看所有镜像列表docker ps 查看运行的容器docker ps -a 查看所有容器docker ps -l 查看上一个执行的容器docker start ID docker stop IDdocker exec -t -i 容器名称 /bin/bash ps:进入到容器内部命令docker logs 容器名称 查看容器日志 Docker主机文件复制到容器中12345docker inspect -f '&#123;&#123;.Id&#125;&#125;' 容器id或名称 ps:获取整个容器完整ID命令docker cp /root/software/demo-web.war 7726a9603a775f4b82e2c271c48d98505bcb2de3b4c53761b740485cc3c7db4a:/root/software/demo-web.warps:7726a..为容器的完整ID]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch5.X Centos7安装过程]]></title>
    <url>%2F2017%2F10%2F19%2Fes-install%2F</url>
    <content type="text"><![CDATA[摘要 Elasticsearch5.X Centos7安装过程。 下载地址：Elasticsearch-5.5.2.tar.gzElasticSearch 安装12345678910111213141516171819202122#Elasticsearch默认不推荐使用root用户启动，所以创建用户#创建用户elastic useradd elastic#设置密码 （回车后输入密码）passwd elastic#切到elastic用户目录下cd /home/elastic#下载Elasticsearch安装包wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.2.tar.gz#解压安装包tar -xzvf elasticsearch-5.5.2.tar.gz#给elastic用户设置文件读写权限chown -R elastic:elastic elasticsearch-5.5.2#切换到elastic用户，并启动elasticsearchsu elasticsh elasticsearch-5.5.2/bin/elasticsearch 启动测试123456789101112131415执行命令 curl http://localhost:9200/#得到以下结果则启动成功&#123; "name" : "_EArkv7", "cluster_name" : "elasticsearch", "cluster_uuid" : "q9gTAC0gTduDqxiV9JgE_g", "version" : &#123; "number" : "5.5.2", "build_hash" : "b2f0c09", "build_date" : "2017-08-14T12:33:14.154Z", "build_snapshot" : false, "lucene_version" : "6.6.0" &#125;, "tagline" : "You Know, for Search"&#125; 主机不能访问虚拟机9200端口编辑Elasticsearch config/elasticsearch.yml 配置文件。 如下图所示 启动过程可能遇到的错误123ERROR: bootstrap checks failed1.max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]2.max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 1.问题一解决方法123456#切换到root用户，编辑limits.conf vi /etc/security/limits.conf#添加如下内容* hard nofile 65536* soft nofile 65536 2.问题二解决方法12345678910#切换到root用户修改配置sysctl.confvi /etc/sysctl.conf#添加下面配置：vm.max_map_count=655360#并执行命令：sysctl -p#重启Elasticsearch]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 设置自启动]]></title>
    <url>%2F2017%2F10%2F19%2Fes-start%2F</url>
    <content type="text"><![CDATA[摘要 Elasticsearch Linux 自启动脚本。 Elasticsearch自启动脚本设置假设文件所在位置为/usr/local/el-start.sh。内容如下 12345678910#!/bin/bashexport JAVA_HOME=/usr/local/java/jdk1.8.0_121export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATHsu - elastic&lt;&lt;!cd /home/elastic/elasticsearch-5.5.2/./bin/elasticsearch -dexit! 脚本解释说明Elasticsearch启动需要jdk支持，故首先设置jdk系统变量 1234export JAVA_HOME=/usr/local/java/jdk1.8.0_121export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH Elasticsearch启动12345678910111213141516#默认不支持root用户启动,切换用户su - elastic#进入Elasticsearch安装目录cd /home/elastic/elasticsearch-5.5.2/#以后台守护进程方式启动./bin/elasticsearch -d#脚本设置完成后执行脚本测试，如果启动成功。则可以将脚本加入系统文件中，系统重启就会自动加载。#编辑文件/etc/rc.d/rc.local#加入/usr/local/el-start.sh]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux防火墙设置]]></title>
    <url>%2F2017%2F10%2F19%2Ffirewall-set%2F</url>
    <content type="text"><![CDATA[摘要 CentOS7 CentOS6防火墙设置相关命令。 在CentOS7中，有很多CentOS 6中的常用服务发生了变化其中iptables是其中比较大的一个。防火墙iptables被firewalld取代 centOS 7关闭防火墙12345678#查看默认防火墙状态（关闭后显示notrunning，开启后显示running）firewall-cmd --state #停止firewallsystemctl stop firewalld.service #禁止firewall开机启动systemctl disable firewalld.service centOS 6关闭防火墙123456789101112131415#可以查看到iptables服务的当前状态service iptables status #关于启动和关闭防火墙的命令:1) 重启后生效开启： chkconfig iptables on关闭： chkconfig iptables off2) 即时生效，重启后失效开启： service iptables start****关闭： service iptables stop]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIT 常用命令]]></title>
    <url>%2F2017%2F10%2F19%2Fgit%2F</url>
    <content type="text"><![CDATA[摘要 Git常用命令记录一下。 Pro Git书籍地址: Pro Git 图解： Workspace： 工作区 Index/Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 命令一、新建代码库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 二、配置Git的设置文件为.gitconfig，它可以在用户住目录下（全局配置），也可以在项目目录下（项目配置） 123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name "[name]"$ git config [--global] user.email "[email address]" 三、增加/删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 四、代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 五、分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 六、标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 七、查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat "@&#123;0 day ago&#125;"# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 八、远程同步123456789101112131415161718192021222324# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url]eg: git remote add origin https://git.coding.net/ghycn/ghycn.coding.com.git# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 九、撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 十、其他12#生成一个可供发布的压缩包$ git archive]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 源文件备份]]></title>
    <url>%2F2017%2F10%2F19%2Fhexo-source-backup%2F</url>
    <content type="text"><![CDATA[摘要 hexo个人静态博客，源文件及主题备份，以防件丢失。 hexo 源文件备份12345678910111213141516171819201.进入到本地hexo博客文件夹所在位置cd /Library/Application/hexo2.将当前位置初始化为代码仓库git init3.设置远程仓库地址git remote add origin https://git.coding.net/ghycn/ghycn.coding.com.git4.创建hexo分支，用来存放源码git checkout -b hexo5.git 文件添加git add .6.git 提交git commit -m "init"7.push到hexo分支git push origin hexo]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA完美激活]]></title>
    <url>%2F2017%2F10%2F19%2Fidea-register%2F</url>
    <content type="text"><![CDATA[摘要 IDEA 超级简单破解教程。 license service address :1http://idea.iteblog.com/key.php]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>IDEA 激活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jsPlumb 基本概念]]></title>
    <url>%2F2017%2F10%2F19%2Fjsplumb%2F</url>
    <content type="text"><![CDATA[摘要 jsPlumb 可用于web流程图，数据库建模工具开发。官网地址 本文主要是jsPlumb 属性方法详解。 jsPlumb 基本概念一、默认属性 Anchor：锚点(连接点位置)，可以设置在任何没有锚点的目标上(endPoint) Anchors：设置在connect的源和目标点的连接点位置，默认是 BottomCenter Connector：连接线（比如：[&quot;Bezier&quot;, {curviness: 63}]为贝塞尔曲线） ConnectionsDetachable：是否在连接点可以用鼠标拖动[true/false] Container：容器 DoNotThrowErrors：设置当锚点(Anchor)、端点(endPoint)和连接器(Connector)不存在的时候是否抛出异常 ConnectionOverlays：默认覆盖附着在每个连接器 DragOptions：为 被 jsPlumb.draggable 设置了拖拽的元素拖拽时设置的css样式.eg:hoverClass: &quot;dropHover&quot;,//释放时指定鼠标停留在该元素上使用的css class; activeClass: &quot;dragActive&quot;//可拖动到的元素使用的css class Endpoint: 端点的形状定义，比如圆：[ &quot;Dot&quot;, { radius:5 } ]；正方形：Rectangle Endpoints：设置了连接器的源和目标端点的形状，eg圆： [ [ &quot;Dot&quot;, { radius:7 } ], [ &quot;Dot&quot;, { radius:11 } ] ] EndpointOverlays:默认覆盖附着在每个端点 EndpointStyle：端点的默认样式 EndpointStyles：设置了连接器的源和目标端点的样式 EndpointHoverStyle：端点的hover状态样式 EndpointHoverStyles ：设置了连接器的源和目标端点端点的hover状态样式 HoverPaintStyle ： LogEnabled：jsPlumb内部日志是否开启。 Overlays：默认覆盖连接器和端点样式，装饰连接器,如标签、箭头等 MaxConnections ：设置连接点最多可以连接几条线 PaintStyle ：设置连接点的样式 connectorStyle：设置连接线样式 ReattachConnections ： RenderMode ：默认渲染模式 Scope：连接点的标识符，只有标识符相同的连接点才能连接 二、锚点(Anchor)1 . 默认锚位置: Top (TopCenter) TopRight Right (RightMiddle) BottomRight Bottom (BottomCenter) BottomLeft Left (LeftMiddle) TopLeft Center eg： 12//定义了一个在底部中间的锚点位置jsPlumb.connect(&#123;...., anchor:"Bottom", ... &#125;); 2 . 基于数组的语法 [x,y,dx,dy] x-相对该锚点在x轴坐标比例（最大1） y-相对该锚点y轴坐标比例（最大1） dx-控制锚的方向 dy-同上 eg： 12//定义了一个在底部中间的锚点位置jsPlumb.connect(&#123;...., anchor:[ 0.5, 1, 0, 1 ], ... &#125;); 如果锚点位置无法满足你的需求，还可以设置锚点的偏移量[x,y,dx,dy,offSetX,offSetY] ,下面设置了Y轴偏移50px，锚点Y坐标会+50px: 1jsPlumb.connect(&#123;...., anchor:[ 0.5, 1, 0, 1, 0, 50 ], ... &#125;); 3 . 动态锚 数组定义 没有特殊的语法来创建一个动态锚;可以提供一个静态数组锚规格,如: 12var dynamicAnchors = [ [ 0.2, 0, 0, -1 ], [ 1, 0.2, 1, 0 ], [ 0.8, 1, 0, 1 ], [ 0, 0.8, -1, 0 ] ];jsPlumb.connect(&#123;...., anchor:dynamicAnchors, ... &#125;); 或者组合： 12var dynamicAnchors = [ [ 0.2, 0, 0, -1 ], [ 1, 0.2, 1, 0 ], "Top", "Bottom" ];jsPlumb.connect(&#123;...., anchor:dynamicAnchors, ... &#125;); 这样锚点会根据位置自动调整到最合适的位置(定义的数组里几个点中) 默认定义 jsPlumb提供了一个动态锚 AutoDefault 选择从 前 , 右 , 底 和 左 : 1jsPlumb.connect(&#123;...., anchor:"AutoDefault", ... &#125;); 4 . 多边形锚 Circle(圆) Ellipse(椭圆) Triangle(三角形) Diamond(菱形) Rectangle(矩形) Square(正方形) (1) 单个多边形eg： 1234jsPlumb.addEndpoint("someElement", &#123; endpoint:"Dot", anchor:[ "Perimeter", &#123; shape:"Circle" &#125; ]&#125;); 如果锚点的宽高一样，该锚点位置为动态圆周。宽高不同为椭圆，类似正方形和矩形。 默认情况下，锚点个数为60，我们还可以手动指定： eg（指定150个动态锚点）： 1234jsPlumb.addEndpoint("someDiv", &#123; endpoint:"Dot", anchor:[ "Perimeter", &#123; shape:"Square", anchorCount:150 &#125;]&#125;); (2) 组合锚点（三角形与菱形）：123456789jsPlumb.connect(&#123; source:"someDiv", target:"someOtherDiv", endpoint:"Dot", anchors:[ [ "Perimeter", &#123; shape:"Triangle" &#125; ], [ "Perimeter", &#123; shape:"Diamond" &#125; ] ]&#125;); (3) 自定义角度多边形锚点123456789jsPlumb.connect(&#123; source:"someDiv", target:"someOtherDiv", endpoint:"Dot", anchors:[ [ "Perimeter", &#123; shape:"Triangle", rotation:25 &#125; ], [ "Perimeter", &#123; shape:"Triangle", rotation:-335 &#125; ] ]&#125;); 上面定义了两个三角形旋转不同角度得到的组合图形（旋转适用带角度的多边形）。 5. CSS类和锚点(1)介绍锚点的不同位置可以有多种css样式，那就要有不同的css类提供支持。 被写入到锚点的CSS类和元素与jsPlumb实例相关联的前缀默认的前缀: 1jsplumb-endpoint-anchor- eg： 123var ep = jsPlumb.addEndpoint("someDiv", &#123; anchor:[0.5, 0, 0, -1, 0, 0, "top" ]&#125;; jsPlumb将会分配这个类给创建的 endpoint 和元素 someDiv： 1jsplumb-endpoint-anchor-top (2)示例一个使用动态锚的例子: 12345678var ep = jsPlumb.addEndpoint("someDiv", &#123; anchor:[ [ 0.5, 0, 0, -1, 0, 0, "top" ], [ 1, 0.5, 1, 0, 0, 0, "right" ] [ 0.5, 1, 0, 1, 0, 0, "bottom" ] [ 0, 0.5, -1, 0, 0, 0, "left" ] ]&#125;); 这里的类分配给端点和元素循环这些值作为锚位置的变化: 1234jsplumb-endpoint-anchor-topjsplumb-endpoint-anchor-rightjsplumb-endpoint-anchor-leftjsplumb-endpoint-anchor-bottom 如果您提供多个类名,jsPlumb不会预先考虑类中的每个词的前缀: 123var ep = jsPlumb.addEndpoint("someDiv", &#123; anchor:[ 0.5, 0, 0, -1, 0, 0, "foo bar" ]&#125;); 会导致2个类被添加到端点和元素: 1jsplumb-endpoint-anchor-foo 和 bar (3)改变锚类前缀前缀 endpointAnchorClass 用于锚类存储为jsPlumb的成员，这个前缀是可更改的: 1jsPlumb.endpointAnchorClass = "anchor_"; 或者 12var jp = jsPlumb.getInstance();jp.endpointAnchorClass = "anchor_"; 三、连接线(器)(Connectors)1. 简介jsPlumb提供了四种连接线： straight(直线) Bezier(贝塞尔曲线) flowchart(流程图) state machine straight在两个端点之间画一条直线。 它支持两个构造函数参数: stub：可选的,默认值为0。此参数的任何正值将导致在与连接线的两端产生一段不可改变方向的线段 gap：可选，默认为0像素。在连接线的一端和连接的元素之间指定一个间隙。 Bezier贝塞尔提供了一个立方的贝塞尔曲线。 它支持一个构造函数参数: curviness：参数可选,默认为150。 定义了曲线的弯曲程度。 flowchart垂直或水平的连接线，提供了四个参数： stub：这是最小长度，以像素为单位，最初的存根，源自一个端点。这是一个可选的参数，并且可以是一个整数，它指定了连接器的每个末端的存根，或是一个整数数组，指定[源目标]端点的连接。默认值为30像素的整数 alwaysRespectStubs ：可选，默认为false。 gap：可选，默认为0像素。在连接线的一端和连接的元素之间指定一个间隙。 midpoint：可选，默认为0.5。这是一个流程图中最长的部分将被绘制的2个元素之间的距离。 cornerRadius：默认为0。此参数的正值将改变弯角的度数。 state machine略微弯曲的线（实际上是二次Bezier曲线），类似于状态机的连接器，支持的构造函数参数： margin：可选；默认为5。定义连接线开始/结束的元素的距离。 curviness：可选的,默认为10，定义了曲线的弯曲程度。 proximityLimit ： 可选,默认为80。 连接线的两端之间的最小距离 它描绘为一条直线而非二次贝塞尔曲线。 四、端点(Endpoints)简介端点是连接里的一个端点外观和行为表现的集合，jsPlumb实现了四个端点： Dot(点) Rectangle(矩形) Blank(空) image(图像) 创建有不同的方式创建 endpoint： (1)connect并通过一个元素id或DOM元素作为源/目标,创建并分配一个新的端点 eg： 12345jpInstance.connect(&#123; source: "state1", target: "state2", scope: "state3"&#125;); (2)addEndpoint创建一个新的端点 1jpInstance.addEndpoint("myDivId", EndpointConfig) (3)makeSource()1jpInstance.makeSource(...) 类型(1)Dot就是在屏幕上画一个点，它支持三个构造函数参数: radius：可选，默认为10像素。 定义点的半径 cssClass ：可选，端点元素的CSS类。 hoverClass 可选的，元素或连线的hover属性样式类 (2)Rectangle绘制一个矩形。 支持构造函数参数有: width：可选的，默认为20像素。定义矩形的宽度。 height：可选的，默认为20像素。定义矩形的高。 cssClass ：可选的，端点元素的CSS类。 hoverClass ：可选的，元素或连线的hover属性样式类 (3)Image从一个指定的URL加载图像，这个端点支持三种构造函数参数: src：图片的url cssClass ：可选的，端点元素的CSS类。 hoverClass ：可选的，元素或连线的hover属性样式类 五、覆盖（连接元素）(Overlays)简介jsPlumb带有五个类型的覆盖图: Arrow(箭头) ：一个可配置的箭头，在某些点上涂上了一个可配置的箭头。你可以控制箭头的长度和宽度，“折返”点一点尾巴分折回来，和方向（允许值为1和1；1是默认的，意味着在连接点方向） Label(标签)：一个可配置的连线标签 PlainArrow(平原箭头)：没有监听的三角形箭头 Diamond(钻石)：钻石箭头 Custom(自定义)：可自定义DOM元素 位置位置表明连接元素在连接线的位置，通常有三种表明方式： [0 . . 1]范围内的十进制数，表明在连接线的位置比例，默认0.5 [1 . . . ] (&gt;1)的数字表明沿着连接线的绝对路径的像素 小于零的整数数组: (1):指定一个覆盖在端点的中心位置： 1location:[ 0.5, 0.5 ] (2):沿着x轴从左上角叠加5像素 1location: [ 5, 0 ] (3):沿着x轴从右下角叠加放置5像素 1location: [ -5, 0 ] 对于位置的操作，jsPlumb提供了两个方法： getLocation ——返回当前位置 setLocation ——设置当前位置 使用使用场景(出现以下调用的时候)： jsPlumb.connect jsPlumb.addEndpoint jsPlumb.makeSource 注： 没有 jsPlumb.makeTarget 1. 在 jsPlumb.connect 被调用时使用(1). 下面指定了 一个默认配置的箭头和一个文字为foo的标签文本： 12345678jsPlumb.connect(&#123; ... overlays:[ "Arrow", [ "Label", &#123; label:"foo", location:0.25, id:"myLabel" &#125; ] ], ...&#125;); 此连接的箭头在连接线的中间，lable标签则是在连接线的四分之一处；这里添加了一个id，它可以在以后移除或修改标签时使用。 (2). 箭头位置位于连接线距离50像素(绝对位置): 12345678jsPlumb.connect(&#123; ... overlays:[ "Arrow", [ "Label", &#123; label:"foo", location:50, id:"myLabel" &#125; ] ], ...&#125;); 2. 在 jsPlumb.addEndpoint 被调用时使用此连接将有10x30像素箭坐落在连接头，标签“foo”则位于中点。端点本身也有一个覆盖，位于[ - 0.5 宽，- 0.5 高]相对于端点的左上角。 1234567891011jsPlumb.addEndpoint("someDiv", &#123; ... overlays:[ [ "Label", &#123; label:"foo", id:"label", location:[-0.5, -0.5] &#125; ] ], connectorOverlays:[ [ "Arrow", &#123; width:10, length:30, location:1, id:"arrow" &#125; ], [ "Label", &#123; label:"foo", id:"label" &#125; ] ], ...&#125;); 注：在addEndpoint 使用 connectorOverlays 代替 overlays，因为 overlays指向端点覆盖。 3. 在 jsPlumb.makeSource同样使用 connectorOverlays，而且 makeSource 支持 endpoint 参数。此连接将有10x30像素箭坐落在连接头，标签“foo”位于中点。 12345678910jsPlumb.makeSource("someDiv", &#123; ... endpoint:&#123; connectorOverlays:[ [ "Arrow", &#123; width:10, length:30, location:1, id:"arrow" &#125; ], [ "Label", &#123; label:"foo", id:"label" &#125; ] ] &#125; ...&#125;); 4. addOverlay 方法Endpoints 和 Connections 都有一个方法： addOverlay，它提供一个单一的方法定义一个 覆盖(Overlays): 12var e = jsPlumb.addEndpoint("someElement");e.addOverlay([ "Arrow", &#123; width:10, height:10, id:"arrow" &#125;]); Overlay Types（覆盖类型）1. Arrow(箭头)一个箭头 使用四个点：头、两个尾点和一个foldback(监听)，它允许箭头的箭尾缩进。此覆盖的可用构造函数参数： width：宽度 length：长度 location：在连接线上的位置 direction：默认1-向前，-1向后 foldback：箭头沿轴到尾点的监听。默认是0.623 paintStyle：Endpoints 和 Connectors 的样式对象 2. PlainArrow（平原箭头）这其实就是一个 foldback=1 的 Arror；继承Arror的构造函数 3. Diamond（菱形）这其实就是一个 foldback=2 的 Arror；继承Arror的构造函数 4. Label（标签）(1) 介绍 提供装饰连接器的文本标签。可用的构造函数参数是： label : 文本显示。 您可以提供一个函数,而不是纯文本:连接作为一个参数传递,它应该返回一个字符串。 cssClass :可选的css类使用的标签。现在优先使用 labelStyle 参数。 labelStyle ： 可选参数标签的外观。 可用参数有： font ：一种适用于画布元素的字体字符串 fillStyle ：标签的背景颜色填充，可选。 color ：字体颜色，可选 padding ：表示标签的宽度的比例，而不是px和ems。 borderWidth ：标签的边框宽度，默认0 borderStyle ：标签边框的样式，可选 location ：标签位置 (2). getLabel 和 setLabel 标签覆盖提供了两个方法 getLabel 和 setLabel 用于动态地get/set标签内容: 1234567891011121314var c = jsPlumb.connect(&#123; source:"d1", target:"d2", overlays:[ [ "Label", &#123;label:"FOO", id:"label"&#125;] ] &#125;); ... var label = c.getOverlay("label");console.log("Label is currently", label.getLabel());label.setLabel("BAR");console.log("Label is now", label.getLabel()); 这个例子里，标签被赋予一个id ‘label’，然后检索这个id动态设置lable的值。 Connections 和Endpoints 都支持 标签覆盖： 1234567891011var conn = jsPlumb.connect(&#123; source:"d1", target:"d2", label:"FOO"&#125;); ... console.log("Label is currently", conn.getLabel());conn.setLabel("BAR");console.log("Label is now", conn.getLabel()); (3). 动态设置label 123456789101112var conn = jsPlumb.connect(&#123; source:"d1", target:"d2"&#125;); ... conn.setLabel(function(c) &#123; var s = new Date(); return s.getTime() + "milliseconds have elapsed since 01/01/1970";&#125;);console.log("Label is now", conn.getLabel()); og(“#### 5. Custom（自定义） jsPlumb允许自定义一个 OverLays，你只需要实现 create(component)： 1234567891011121314151617var conn = jsPlumb.connect(&#123; source:"d1", target:"d2", paintStyle:&#123; strokeStyle:"red", lineWidth:3 &#125;, overlays:[ ["Custom", &#123; create:function(component) &#123; return $("&lt;select id='myDropDown'&gt;&lt;option value='foo'&gt;foo&lt;/option&gt;&lt;option value='bar'&gt;bar&lt;/option&gt;&lt;/select&gt;"); &#125;, location:0.7, id:"customOverlay" &#125;] ]&#125;); 注意 此处的id为 customeOverlay ，你可以在 Connection 或者 Endpoint上使用 getOverlay(id) 方法。 隐藏/显示 Overlays（覆盖）可以使用 setVisible 方法控制 Overlays 的显示属性，或者在一个连接上使用 showOverlay(id) 和 hideOverlay(id)。 (1). 使用id： 1234567891011121314151617var connection = jsPlumb.connect(&#123; ... overlays:[ "Arrow", [ "Label", &#123; label:"foo", location:0.25, id:"myLabel" &#125; ] ], ... &#125;); // time passes var overlay = connection.getOverlay("myLabel"); // now you can hide this Overlay: overlay.setVisible(false); // there are also hide/show methods: overlay.show(); overlay.hide(); (2). 使用 showOverlay(id) 和 hideOverlay(id)： Connection 和 Endpoint 可以使用showOverlay(id) 和 hideOverlay(id)： 12345678910111213141516var connection = jsPlumb.connect(&#123; ... overlays:[ "Arrow", [ "Label", &#123; label:"foo", location:-30 , id:"myLabel" &#125;] ], ...&#125;); // time passes connection.hideOverlay("myLabel"); // more time passes connection.showOverlay("myLabel"); 删除 Overlays(覆盖)123456789101112var connection = jsPlumb.connect(&#123; ... overlays:[ "Arrow", [ "Label", &#123; label:"foo", location:0.25 , id:"myLabel"&#125; ] ], ...&#125;); // time passes connection.removeOverlay("myLabel");]]></content>
      <categories>
        <category>jQuery插件-jsPlumb</category>
      </categories>
      <tags>
        <tag>jsPlumb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2F2017%2F10%2F19%2Flinux%2F</url>
    <content type="text"><![CDATA[摘要 Linux常用的基础命令，记录一下。 Linux命令网址：Linux命令大全 Linux常用命令12345678#给文件夹授权chmod -R 777 /home/data#给.sh后缀文件授权chmod u+x *.sh#Kill进程kill -s 9 xxxx java环境变量设置12345678910111213#编辑配置文件vim /etc/profile #添加以下内容export JAVA_HOME=/usr/local/java/jdk1.7.0_79export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar#配置文件生效source /etc/profile#查看环境变量配置是否成功java -version Tomcat命令12345#查看tomcat启动线程ps -ef | grep tomcat #查看tomcat日志 tail -f catalina.out 子目录中的文件移动到上一目录1mv 子目录/* ./ 解压命令1234567891011121314151617#解压 tar包tar -xvf file.tar #解压tar.gztar -xzvf file.tar.gz #解压 tar.bz2tar -xjvf file.tar.bz2 #解压tar.Ztar -xZvf file.tar.Z #解压rarunrar e file.rar #解压zipunzip file.zip]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下多版本JDK配置]]></title>
    <url>%2F2017%2F10%2F19%2Fmac-jdk%2F</url>
    <content type="text"><![CDATA[摘要 Mac下多版本JDK配置，动态切换JDK版本。 一.下载1链接:http://pan.baidu.com/s/1dFjcdrV 密码:mmt3 二.安装12JDK默认安装路径为/Library/Java/JavaVirtualMachines多版本安装后效果为 三.设置123456789101112131415161718192021221.执行以下命令 cd ~ open -e .bash_profile #打开.bash_profile文件 #注:假如.bash_profile文件不存在执行下面命令新建文件 cd ~ touch .bash_profile #新建.bash_profile文件 ls -a #查看文件是否创建成功 2.在打开的.bash_profile文件中添加下面内容然后关闭 #添加JDK的环境变量 export JAVA_7_HOME=/Library/Java/JavaVirtualMachines/ jdk1.7.0_79.jdk/Contents/Home export JAVA_8_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home #默认JDK1.7 export JAVA_HOME=$JAVA_7_HOME #alias命令动态切换JDK版本 alias jdk7="export JAVA_HOME=$JAVA_7_HOME" alias jdk8="export JAVA_HOME=$JAVA_8_HOME"3.设置生效 cd ~ source .bash_profile #设置配置立即生效 四.验证是否安装成功]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>Mac jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 安装]]></title>
    <url>%2F2017%2F10%2F19%2Fmysql-install%2F</url>
    <content type="text"><![CDATA[摘要 yum方式安装Mysql 一.安装步骤123456789101112131415161718#在mysql官网下载mysql的repo源https://dev.mysql.com/downloads/repo/yum/#找到适合操作系统的repo源后下载wget https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm#安装mysql57-community-release-el7-11.noarch.rpm包rpm -ivh mysql57-community-release-el7-11.noarch.rpm#ps:安装这个包后，会获得两个mysql的yum repo源/etc/yum.repos.d/mysql-community.repo/etc/yum.repos.d/mysql-community-source.repo#安装mysql（在线下载所需安装包）yum install mysql-server#启动mysqlservice mysqld start 二.获取随机密码Mysql安装完成后，自动生成一个随机密码，可以使用随机密码登录 12345678910#获取随机密码grep 'temporary password' /var/log/mysqld.log#命令运行后得到下面一句字符串，其中`s6OD/*I6(!hN`就是密码2017-09-11T03:10:07.036618Z 1 [Note] A temporary password is generated for root@localhost: s6OD/*I6(!hN#使用随机密码登录mysqlmysql -uroot -p#输入密码即可登录 三.修改Mysql密码1234567891011121314151617181920212223242526#修改mysql配置文件vim /etc/my.cnf#在 [mysqld] 小节下添加一行skip-grant-tables=1#这一行配置让 mysqld 启动时不对密码进行验证#重启 mysqld 服务service mysqld restart#使用 root 用户登录到 mysqlmysql -u root#修改密码update mysql.user set authentication_string=password('123456') where user='root';#Mysql默认有密码强度限制，不能设置简单密码mysql&gt; set global validate_password_policy=0;mysql&gt; set global validate_password_length=1;#去掉免密配置删除/etc/my.cnf 文件中的skip-grant-tables=1#重启mysql即可service mysqld restart 四.卸载mysql1yum -y remove mysql* 五.表名大小写设置mysql默认在linux环境下区分大小写，在windows环境不区分 1234567#用root登录，vim /etc/my.cnf#在[mysqld]节点下，加入一行lower_case_table_names=1#重启MySQL即可 六.允许远程访问设置12345678#允许所有地址访问GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY'mypassword' WITH GRANT OPTION; #如果是固定ip就这么写GRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.1.1' IDENTIFIED BY 'mypassword' WITH GRANT OPTION; #使授权生效mysql&gt;FLUSH PRIVILEGES]]></content>
      <categories>
        <category>mysql 安装</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 建库语句]]></title>
    <url>%2F2017%2F10%2F19%2Foracle%2F</url>
    <content type="text"><![CDATA[摘要 Oracle 建库语句。 Oracle 建库共分为四步第1步：创建临时表空间123456create temporary tablespace user_temp tempfile 'D:\oracle\oradata\Oracle9i\user_temp.dbf' size 50m autoextend on next 50m maxsize 20480m extent management local; 第2步：创建数据表空间1234567create tablespace user_data logging datafile 'D:\oracle\oradata\Oracle9i\user_data.dbf' size 50m autoextend on next 50m maxsize 20480m extent management local; 第3步：创建用户并指定表空间123create user username identified by password default tablespace user_data temporary tablespace user_temp; 第4步：给用户授予权限1grant connect,resource,dba to username;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle建库语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring动态开启，关闭定时任务]]></title>
    <url>%2F2017%2F10%2F17%2Fspring-quartz%2F</url>
    <content type="text"><![CDATA[摘要 Spring动态开启，关闭定时任务 123456789101112131415161718192021222324252627282930313233343536373839@Autowiredprivate ThreadPoolTaskScheduler threadPoolTaskScheduler;public static ScheduledFuture&lt;?&gt; future = null;//开启定时任务public void startCron() &#123; String cron = ""; String hour= backupTime.split(":")[0]; String minute = backupTime.split(":")[1]; if("1".endsWith(period))&#123;//如果周期是月 //"0 15 10 15 * ?" 每月15日上午10:15触发 cron = "0 "+minute+" "+hour+" 1 * ?";//每月1号触发 &#125;else if("2".endsWith(period))&#123;//如果周期是周 //0 59 2 ? * FRI 每周5凌晨2点59分触发 cron = "0 "+minute+" "+hour+" ? * MON";//每周一触发 &#125;else if("3".endsWith(period))&#123;//如果周期是日 //"0 0 12 * * ?" 每天中午12点触发 cron = "0 "+minute+" "+hour+" * * ?";//每日触发 &#125; if (future != null) &#123; future.cancel(true); &#125; System.out.println("《==================定时开启时间："+cron); //cron="0/15 * * * * *"; future = threadPoolTaskScheduler.schedule(new InitUtil(dataBackupService,logService,0), new CronTrigger(cron)); logService.saveLog("开启数据库自动备份任务", Operation.DATA_BACKUP);&#125;//关闭定时任务 public void stopCron() &#123; if (future != null) &#123; future.cancel(true); &#125;&#125;]]></content>
      <categories>
        <category>Spring定时任务</category>
      </categories>
      <tags>
        <tag>定时任务</tag>
      </tags>
  </entry>
</search>
